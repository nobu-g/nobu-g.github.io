<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Nobuhiro Ueda</title><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" data-next-head=""/><meta name="description" content="This is the homepage of Nobuhiro Ueda. About his research and education." data-next-head=""/><link rel="icon" href="/favicon.ico" data-next-head=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;700&amp;display=swap" rel="stylesheet"/><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;700&amp;display=swap" rel="stylesheet"/><link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital@0;1&amp;family=Open+Sans:wght@400;700&amp;display=swap" rel="stylesheet"/><link rel="preload" href="/_next/static/css/689184f8d41fa046.css" as="style"/><link rel="stylesheet" href="/_next/static/css/689184f8d41fa046.css" data-n-g=""/><link rel="preload" href="/_next/static/css/13d9728298296572.css" as="style"/><link rel="stylesheet" href="/_next/static/css/13d9728298296572.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-8cac0b4b405cede1.js" defer=""></script><script src="/_next/static/chunks/framework-ee17a4c43a44d3e2.js" defer=""></script><script src="/_next/static/chunks/main-e109fad1a6b91f85.js" defer=""></script><script src="/_next/static/chunks/pages/_app-baf32c95c76abe3a.js" defer=""></script><script src="/_next/static/chunks/e95b820e-6cb254e374f6f07e.js" defer=""></script><script src="/_next/static/chunks/0465ed09-e30c145aaaea9778.js" defer=""></script><script src="/_next/static/chunks/393-79cba27cefa86c0a.js" defer=""></script><script src="/_next/static/chunks/pages/index-7829386bba3a872e.js" defer=""></script><script src="/_next/static/s-4YCiVsa_14CEoif0VFY/_buildManifest.js" defer=""></script><script src="/_next/static/s-4YCiVsa_14CEoif0VFY/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="App"><header id="home" class="Header_header__SQD4u"><nav id="nav-wrap" class="Header_nav-wrap__IcFrBfalse"><a class="Header_mobile-btn__WAWKE" href="#nav-wrap" title="Show navigation">Show navigation</a><a class="Header_mobile-btn__WAWKE" href="#home" title="Hide navigation">Hide navigation</a><ul id="nav" class="nav"><li class="current"><a class="smoothscroll" href="#home">Home</a></li><li class=""><a class="smoothscroll" href="#about">About</a></li><li class=""><a class="smoothscroll" href="#resume">Resume</a></li><li class=""><a class="smoothscroll" href="#portfolio">Works</a></li></ul></nav><div class="Header_banner__M3pyx row"><div class="Header_banner-text__nh_M4"><h1 class="responsive-headline">I&#x27;m <!-- -->Nobuhiro Ueda<!-- -->.</h1><h3>I am a researcher at the Data Science Laboratory, NEC Corporation. I received my Ph.D. in Informatics. I am working on R&amp;D of large language models and natural language processing.</h3><hr/><ul class="Header_social___kSme"><li><a href="https://www.linkedin.com/in/nobuhiro-ueda-9163b91b7/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></a></li><li><a href="https://github.com/nobu-g"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://skype.com"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M424.7 299.8c2.9-14 4.7-28.9 4.7-43.8 0-113.5-91.9-205.3-205.3-205.3-14.9 0-29.7 1.7-43.8 4.7C161.3 40.7 137.7 32 112 32 50.2 32 0 82.2 0 144c0 25.7 8.7 49.3 23.3 68.2-2.9 14-4.7 28.9-4.7 43.8 0 113.5 91.9 205.3 205.3 205.3 14.9 0 29.7-1.7 43.8-4.7 19 14.6 42.6 23.3 68.2 23.3 61.8 0 112-50.2 112-112 .1-25.6-8.6-49.2-23.2-68.1zm-194.6 91.5c-65.6 0-120.5-29.2-120.5-65 0-16 9-30.6 29.5-30.6 31.2 0 34.1 44.9 88.1 44.9 25.7 0 42.3-11.4 42.3-26.3 0-18.7-16-21.6-42-28-62.5-15.4-117.8-22-117.8-87.2 0-59.2 58.6-81.1 109.1-81.1 55.1 0 110.8 21.9 110.8 55.4 0 16.9-11.4 31.8-30.3 31.8-28.3 0-29.2-33.5-75-33.5-25.7 0-42 7-42 22.5 0 19.8 20.8 21.8 69.1 33 41.4 9.3 90.7 26.8 90.7 77.6 0 59.1-57.1 86.5-112 86.5z"></path></svg></a></li></ul></div></div><p class="Header_scrolldown__gPrYz"><a class="smoothscroll" href="/#about"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M48 256c0 114.9 93.1 208 208 208s208-93.1 208-208S370.9 48 256 48 48 141.1 48 256zm289.1-43.4c7.5-7.5 19.8-7.5 27.3 0 3.8 3.8 5.6 8.7 5.6 13.6s-1.9 9.9-5.7 13.7l-94.3 94c-7.6 6.9-19.3 6.7-26.6-.6l-95.7-95.4c-7.5-7.5-7.6-19.7 0-27.3 7.5-7.5 19.7-7.6 27.3 0l81.1 81.9 81-79.9z"></path></svg></a></p></header><main><span style="font-size:0"></span><span style="font-size:0"></span><section id="about" class="About_about__rIaNG"><div class="row"><div class="three columns"><img alt="Nobuhiro Ueda Profile Pic" loading="lazy" width="120" height="120" decoding="async" data-nimg="1" class="About_profile-pic__dIu01" style="color:transparent" src="/images/profile.jpg"/></div><div class="nine columns About_main-col__LpPZM"><h2>About Me</h2><p>I am a researcher at the Data Science Laboratory, NEC Corporation, Japan. I&#x27;m interested in how we can make computers understand natural language. Previously, I was working on a research about anaphora resolution in Japanese. Try<!-- --> <a href="https://lotus.kuee.kyoto-u.ac.jp/cohesion-analysis/pub/" target="_blank" rel="noreferrer noopener">our Japanese anaphora resolution demo</a>.</p><div class="row"><div class="columns About_contact-details__VZ4DS"><h2>Contact Details</h2><p class="address"><span>Nobuhiro Ueda</span><br/><span>NEC Tamagawa Office, NEC Corporation<br/>Nakahara-ku Shimonumabe 1753, Kawasaki, Kanagawa, 211-0011, Japan</span><br/><span>ueda at nlp.ist.i.kyoto-u.ac.jp</span></p></div></div></div></div></section><span style="font-size:0"></span><section id="resume" class="Resume_resume__ap4oh"><div class="row Resume_education__1oqQi"><div class="three columns Resume_header-col__9HynL"><h1><span>Education</span></h1></div><div class="nine columns Resume_main-col__skszJ"><div class="row item"><div class="twelve columns"><div><h3 class="Resume_h3__HBgwD">Graduate School of Informatics, Kyoto University</h3><p class="Resume_info__gm_Mt">Ph.D. of Informatics<!-- --> <span>•</span><em class="Resume_date__prsBc">April 2021 - March 2024</em></p><p>Worked on research about natural language processing.</p></div><div><h3 class="Resume_h3__HBgwD">Graduate School of Informatics, Kyoto University</h3><p class="Resume_info__gm_Mt">Master of Informatics<!-- --> <span>•</span><em class="Resume_date__prsBc">April 2019 - March 2021</em></p><p>Worked on research about natural language processing.</p></div><div><h3 class="Resume_h3__HBgwD">Faculty of Engineering, Kyoto University</h3><p class="Resume_info__gm_Mt">Bachelor of Engineering<!-- --> <span>•</span><em class="Resume_date__prsBc">April 2015 - March 2019</em></p><p>Learned about a wide range of engineering topics, including calculus, linear algebra, statistics, electronics, electromagnetism, and computer science.</p></div></div></div></div></div><div class="row Resume_publication__Mp6u3"><div class="three columns Resume_header-col__9HynL"><h1><span>Publications</span></h1></div><div class="nine columns Resume_main-col__skszJ"><div class="row item"><div class="twelve columns"><div><h3>International Conferences and Workshops (Peer-reviewed)</h3><ul><li><h4>J-CRe3: A Japanese Conversation Dataset for Real-world Reference Resolution</h4><p><span><u>Nobuhiro Ueda</u>, Hideko Habe, Yoko Matsui, Akishige Yuguchi, Seiya Kawano, Yasutomo Kawanishi, Sadao Kurohashi and Koichiro Yoshino</span><br/>Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), Turin, Italy, (2024.5).<br/><span>[<a href="https://arxiv.org/abs/2403.19259">paper</a>]</span><span>[<a href="https://github.com/riken-grp/J-CRe3">dataset</a>]</span><span>[<a href="https://github.com/riken-grp/multimodal-reference">code</a>]</span><span>[<a href="/pub/LREC-COLING2024_poster.pdf">poster</a>]</span></p></li><li><h4>Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese</h4><p><span>Yikun Sun, Zhen Wan, <u>Nobuhiro Ueda</u>, Sakiko Yahata, Fei Cheng, Chenhui Chu and Sadao Kurohashi</span><br/>Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), Turin, Italy, (2024.5).<br/><span>[<a href="https://arxiv.org/abs/2403.03690">paper</a>]</span><span>[<a href="https://github.com/hitoshizuku7/awesome-Ja-self-instruct">dataset</a>]</span><span>[<a href="https://github.com/ku-nlp/ja-vicuna-qa-benchmark">code</a>]</span></p></li><li><h4>KWJA: A Unified Japanese Analyzer Based on Foundation Models</h4><p><span><u>Nobuhiro Ueda</u>, Kazumasa Omura, Takashi Kodama, Hirokazu Kiyomaru, Yugo Murawaki, Daisuke Kawahara and Sadao Kurohashi</span><br/>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023): System Demonstrations, Toronto, Canada, (2023.7).<br/><span>[<a href="https://aclanthology.org/2023.acl-demo.52.pdf">paper</a>]</span><span>[<a href="https://github.com/ku-nlp/kwja">code</a>]</span><span>[<a href="https://lotus.kuee.kyoto-u.ac.jp/kwja/index">demo</a>]</span><span>[<a href="/pub/ACL2023_poster.pdf">poster</a>]</span></p></li><li><h4>Improving Bridging Reference Resolution using Continuous Essentiality from Crowdsourcing</h4><p><span><u>Nobuhiro Ueda</u> and Sadao Kurohashi</span><br/>Proceedings of the Fifth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2022), Gyeongju, Republic of Korea, (2022.10).<br/><span>[<a href="https://aclanthology.org/2022.crac-1.8.pdf">paper</a>]</span><span>[<a href="https://github.com/nobu-g/bridging-resolution">code1</a>]</span><span>[<a href="https://github.com/nobu-g/bridging-annotation">code2</a>]</span><span>[<a href="/pub/CRAC2022_slides.pdf">slides</a>]</span></p></li><li><h4>BERT-based Cohesion Analysis of Japanese Texts</h4><p><span><u>Nobuhiro Ueda</u>, Daisuke Kawahara and Sadao Kurohashi</span><br/>Proceedings of the 28th International Conference on Computational Linguistics (COLING 2020), Online, (2020.12).<br/><span>[<a href="/pub/COLING2020.pdf">paper</a>]</span><span>[<a href="https://github.com/nobu-g/cohesion-analysis">code</a>]</span><span>[<a href="/pub/COLING2020_errata.pdf">errata</a>]</span></p></li><li><h4>A System for Worldwide COVID-19 Information Aggregation</h4><p><span>Akiko Aizawa, Frederic Bergeron, Junjie Chen, Fei Cheng, Katsuhiko Hayashi, Kentaro Inui, Hiroyoshi Ito, Daisuke Kawahara, Masaru Kitsuregawa, Hirokazu Kiyomaru, Masaki Kobayashi, Takashi Kodama, Sadao Kurohashi, Qianying Liu, Masaki Matsubara, Yusuke Miyao, Atsuyuki Morishima, Yugo Murawaki, Kazumasa Omura, Haiyue Song, Eiichiro Sumita, Shinji Suzuki, Ribeka Tanaka, Yu Tanaka, Masashi Toyoda, <u>Nobuhiro Ueda</u>, Honai Ueoka, Masao Utiyama, Ying Zhong</span><br/>Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP 2020, Online, (2020.12).<br/><span>[<a href="/pub/EMNLPWS2020.pdf">paper</a>]</span><span>[<a href="https://lotus.kuee.kyoto-u.ac.jp/NLPforCOVID-19/en">url</a>]</span></p></li></ul></div><div><h3>Domestic Journals</h3><ul><li><h4>J-CRe3: 実世界における参照関係解決のための日本語対話データセット</h4><p><span><u>植田 暢大</u>, 波部 英子, 松井 陽子, 湯口 彰重, 河野 誠也, 川西 康友, 黒橋 禎夫, 吉野 幸一郎</span><br/>自然言語処理, Vol31, No.3, (2024.9).<br/><span>[<a href="https://www.jstage.jst.go.jp/article/jnlp/31/3/31_1107/_pdf/-char/ja">paper</a>]</span></p></li></ul></div><div><h3>Domestic Conferences</h3><ul><li><h4>実世界対話における参照関係の統合的解析</h4><p><span>稲積 駿, <u>植田 暢大</u>, 吉野 幸一郎</span><br/>言語処理学会 第31回年次大会, 長崎, (2025.3).<br/><span>[<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q7-13.pdf">paper</a>]</span><span>[<a href="/pub/NLP2025_poster.pdf">poster</a>]</span></p></li><li><h4>実世界対話におけるフレーズグラウンディングモデルの評価と分析</h4><p><span><u>植田 暢大</u>, 波部 英子, 松井 陽子, 湯口 彰重, 河野 誠也, 川西 康友, 黒橋 禎夫, 吉野 幸一郎</span><br/>言語処理学会 第30回年次大会, 神戸, (2024.3).<br/><span>[<a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/E1-4.pdf">paper</a>]</span><span>[<a href="/pub/NLP2024a_slides.pdf">slides</a>]</span></p></li><li><h4>llm-jp-eval: 日本語大規模言語モデルの自動評価ツール</h4><p><span>Namgi Han, <u>植田 暢大</u>, 大嶽 匡俊, 勝又 智, 鎌田 啓輔, 清丸 寛一, 児玉 貴志, 菅原 朔, Bowen Chen, 松田 寛, 宮尾 祐介, 村脇 有吾, 劉 弘毅</span><br/>言語処理学会 第30回年次大会, 神戸, (2024.3).<br/><span>[<a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A8-2.pdf">paper</a>]</span><span>[<a href="/pub/NLP2024b_slides.pdf">slides</a>]</span></p></li><li><h4>実世界における総合的参照解析を目的としたマルチモーダル対話データセットの構築</h4><p><span><u>植田 暢大</u>, 波部 英子, 湯口 彰重, 河野 誠也, 川西 康友, 黒橋 禎夫, 吉野 幸一郎</span><br/>言語処理学会 第29回年次大会, 沖縄, (2023.3).<br/><span>[<a href="https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/H12-1.pdf">paper</a>]</span><span>[<a href="/pub/NLP2023_slides.pdf">slides</a>]</span><img alt="Award Icon" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" style="color:transparent;vertical-align:middle;margin-left:1rem;margin-right:.5rem" src="/images/award.png"/><span>委員特別賞</span></p></li><li><h4>テキスト生成モデルによる日本語形態素解析</h4><p><span>児玉 貴志, <u>植田 暢大</u>, 大村 和正, 清丸 寛一, 村脇 有吾, 河原 大輔, 黒橋 禎夫</span><br/>言語処理学会 第29回年次大会, 沖縄, (2023.3).<br/><span>[<a href="https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/C2-3.pdf">paper</a>]</span><span>[<a href="https://github.com/ku-nlp/kwja">code</a>]</span></p></li><li><h4>KWJA：汎用言語モデルに基づく日本語解析器</h4><p><span><u>植田 暢大</u>, 大村 和正, 児玉 貴志, 清丸 寛一, 村脇 有吾, 河原 大輔 and 黒橋 禎夫</span><br/>情報処理学会 第253回自然言語処理研究会, 京都, (2022.9).<br/><span>[<a href="https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&amp;active_action=repository_view_main_item_detail&amp;item_id=220232&amp;item_no=1&amp;page_id=13&amp;block_id=8">paper</a>]</span><span>[<a href="https://github.com/ku-nlp/kwja">code</a>]</span><span>[<a href="https://speakerdeck.com/nobug/kyoto-waseda-japanese-analyzer">slides</a>]</span><img alt="Award Icon" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" style="color:transparent;vertical-align:middle;margin-left:1rem;margin-right:.5rem" src="/images/award.png"/><span>優秀研究賞</span></p></li><li><h4>BERTとRefinementネットワークによる統合的照応・共参照解析</h4><p><span><u>植田 暢大</u>, 河原 大輔, 黒橋 禎夫</span><br/>言語処理学会 第26回年次大会, 茨城, (2020.3).<br/><span>[<a href="/pub/NLP2020a.pdf">paper</a>]</span><img alt="Award Icon" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" style="color:transparent;vertical-align:middle;margin-left:1rem;margin-right:.5rem" src="/images/award.png"/><span>若手奨励賞</span></p></li><li><h4>因果関係グラフ: 構造的言語処理に基づくイベントの原因・結果・解決策の集約</h4><p><span>清丸 寛一, <u>植田 暢大</u>, 児玉 貴志, 田中 佑, 岸本 裕大, 田中 リベカ, 河原 大輔, 黒橋 禎夫</span><br/>言語処理学会 第26回年次大会, 茨城, (2020.3).<br/><span>[<a href="/pub/NLP2020b.pdf">paper</a>]</span></p></li></ul></div><div><h3>Ph.D. Thesis</h3><ul><li><h4>Cohesion Analysis of Textual and Visual Entities: Enhancing Accuracy and Comprehensiveness</h4><p><span><u>Nobuhiro Ueda</u></span><br/>Ph.D. Thesis, Kyoto University, (2025.3).<br/></p></li></ul></div></div></div></div></div><div class="row Resume_experience__Etduc"><div class="three columns Resume_header-col__9HynL"><h1><span>Experience</span></h1></div><div class="nine columns Resume_main-col__skszJ"><div><h3>researcher</h3><ul><li><h4>NEC Corporation</h4><p class="Resume_info__gm_Mt">Kawasaki, Kanagawa<span>•</span><em class="Resume_date__prsBc">April 2024 - Present</em><br/>[<a href="https://www.nec.com/">website</a>]</p></li></ul></div><div><h3>hackathon</h3><ul><li><h4>16th Young Researcher Association for NLP Studies (YANS) Symposium Hackathon</h4><p class="Resume_info__gm_Mt">Online<span>•</span><em class="Resume_date__prsBc">August 2021</em><br/>[<a href="https://yans.anlp.jp/entry/yans2021report">report</a>]<!-- -->[<a href="https://github.com/upura/yans2021-hackathon">code</a>]<img alt="Award Icon" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" style="color:transparent;vertical-align:middle;margin-left:1rem;margin-right:.5rem" src="/images/award.png"/><span>2nd place</span></p></li></ul></div><div><h3>teaching assistant</h3><ul><li><h4>「人を知る」人工知能講座2022</h4><p class="Resume_info__gm_Mt">Online<span>•</span><em class="Resume_date__prsBc">November 2022</em><br/>[<a href="https://www.kyodai-original.co.jp/jinkouchinou2022/">website</a>]</p></li><li><h4>「人を知る」人工知能講座2021</h4><p class="Resume_info__gm_Mt">Online<span>•</span><em class="Resume_date__prsBc">November 2021</em><br/>[<a href="https://www.kyodai-original.co.jp/jinkouchinou2021/">website</a>]</p></li><li><h4>C Programming Class (2021)</h4><p class="Resume_info__gm_Mt">Kyoto University, Kyoto<span>•</span><em class="Resume_date__prsBc">April 2021 - July 2021</em><br/></p></li><li><h4>「人を知る」人工知能講座2020</h4><p class="Resume_info__gm_Mt">Online<span>•</span><em class="Resume_date__prsBc">November 2020</em><br/>[<a href="https://www.kyodai-original.co.jp/jinkouchinou2020/">website</a>]</p></li><li><h4>「人を知る」人工知能講座2019</h4><p class="Resume_info__gm_Mt">Shin-marunouchi Building, Tokyo<span>•</span><em class="Resume_date__prsBc">November 2019</em><br/>[<a href="https://www.kyodai-original.co.jp/jinkouchinou2019/">website</a>]</p></li><li><h4>C Programming Class (2019)</h4><p class="Resume_info__gm_Mt">Kyoto University, Kyoto<span>•</span><em class="Resume_date__prsBc">April 2019 - July 2019</em><br/></p></li></ul></div><div><h3>internship</h3><ul><li><h4>M3, Inc.</h4><p class="Resume_info__gm_Mt">Akasaka Intercity, Tokyo<span>•</span><em class="Resume_date__prsBc">September 2019</em><br/>Worked on improving recommendation system for medical articles.<br/></p></li><li><h4>LINE</h4><p class="Resume_info__gm_Mt">LINE KYOTO, Kyoto<span>•</span><em class="Resume_date__prsBc">August 2019</em><br/>Joined a hackathon to develop an application like Akinator, which runs on LINE.<br/>[<a href="https://engineering.linecorp.com/ja/blog/kyoto-intern2019/">report</a>]</p></li></ul></div><div><h3>presentation &amp; talks</h3><ul><li><h4>日本語DeBERTaモデルの構築 (JLR2023)</h4><p class="Resume_info__gm_Mt">Okinawa Convention Center, Okinawa<span>•</span><em class="Resume_date__prsBc">March 2023</em><br/>Gave a lightning talk on Japanese foundation models I developed.<br/>[<a href="https://jedworkshop.github.io/JLR2023/program/">website</a>]<!-- -->[<a href="/pub/JLR2023.pdf">slides</a>]</p></li><li><h4>自然言語の意味理解に向けた名詞や述語間の関係解析</h4><p class="Resume_info__gm_Mt">15th ICT innovation, Kyoto University<span>•</span><em class="Resume_date__prsBc">February 2021</em><br/>Gave a poster presentation on my research.<br/>[<a href="https://ict-nw.i.kyoto-u.ac.jp/ict-innovation/15th/">website</a>]<!-- -->[<a href="/pub/ICT_innovation_16th.pdf">poster</a>]</p></li></ul></div></div></div><div class="row undefined"><div class="three columns Resume_header-col__9HynL"><h1><span>Honors</span></h1></div><div class="nine columns Resume_main-col__skszJ"><div><h3>Informatics, AI, and Data Science Fellowship for Doctoral Talent</h3><p class="Resume_info__gm_Mt"><em class="Resume_date__prsBc">April 2021 - March 2024</em><br/>[<a href="https://www.i.kyoto-u.ac.jp/fellowship/">website</a>]</p></div><div><h3>2nd place in 16th Young Researcher Association for NLP Studies (YANS) Symposium Hackathon</h3><p class="Resume_info__gm_Mt"><em class="Resume_date__prsBc">August 2022</em><br/>[<a href="https://yans.anlp.jp/entry/yans2021report">report</a>]<!-- -->[<a href="https://github.com/upura/yans2021-hackathon">code</a>]</p></div></div></div></section><span style="font-size:0"></span><section id="portfolio"><div class="row"><div class="twelve columns collapsed"><h1>Check Out Some of My Works.</h1><div id="portfolio-wrapper" class="bgrid-quarters s-bgrid-thirds cf"><div class="columns portfolio-item"><div class="item-wrap"><a href="https://github.com/ku-nlp/kwja" title="kwja"><img alt="kwja" loading="lazy" decoding="async" data-nimg="1" style="color:transparent" src="images/portfolio/kwja.png"/><div class="overlay"><div class="portfolio-item-meta"><h5>kwja</h5><p>A unified language analyzer for Japanese</p></div></div><div class="link-icon"><i class="fa fa-link"></i></div></a></div></div><div class="columns portfolio-item"><div class="item-wrap"><a href="https://github.com/nobu-g/cohesion-analysis" title="cohesion-analysis"><img alt="cohesion-analysis" loading="lazy" decoding="async" data-nimg="1" style="color:transparent" src="images/portfolio/cohesion-analysis.png"/><div class="overlay"><div class="portfolio-item-meta"><h5>cohesion-analysis</h5><p>A BERT based Japanese cohesion analyzer</p></div></div><div class="link-icon"><i class="fa fa-link"></i></div></a></div></div><div class="columns portfolio-item"><div class="item-wrap"><a href="https://github.com/nobu-g/10cc" title="10cc"><img alt="10cc" loading="lazy" decoding="async" data-nimg="1" style="color:transparent" src="images/portfolio/10cc.jpg"/><div class="overlay"><div class="portfolio-item-meta"><h5>10cc</h5><p>C compiler from scratch</p></div></div><div class="link-icon"><i class="fa fa-link"></i></div></a></div></div><div class="columns portfolio-item"><div class="item-wrap"><a href="https://github.com/chomin/Music-Game" title="Music-Game"><img alt="Music-Game" loading="lazy" decoding="async" data-nimg="1" style="color:transparent" src="images/portfolio/music-game-kari.png"/><div class="overlay"><div class="portfolio-item-meta"><h5>Music-Game</h5><p>Rhythm video game for iOS</p></div></div><div class="link-icon"><i class="fa fa-link"></i></div></a></div></div></div></div></div></section></main><footer><div class="row"><div class="twelve columns"><ul class="social-links"><li><a href="https://www.linkedin.com/in/nobuhiro-ueda-9163b91b7/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></a></li><li><a href="https://github.com/nobu-g"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://skype.com"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M424.7 299.8c2.9-14 4.7-28.9 4.7-43.8 0-113.5-91.9-205.3-205.3-205.3-14.9 0-29.7 1.7-43.8 4.7C161.3 40.7 137.7 32 112 32 50.2 32 0 82.2 0 144c0 25.7 8.7 49.3 23.3 68.2-2.9 14-4.7 28.9-4.7 43.8 0 113.5 91.9 205.3 205.3 205.3 14.9 0 29.7-1.7 43.8-4.7 19 14.6 42.6 23.3 68.2 23.3 61.8 0 112-50.2 112-112 .1-25.6-8.6-49.2-23.2-68.1zm-194.6 91.5c-65.6 0-120.5-29.2-120.5-65 0-16 9-30.6 29.5-30.6 31.2 0 34.1 44.9 88.1 44.9 25.7 0 42.3-11.4 42.3-26.3 0-18.7-16-21.6-42-28-62.5-15.4-117.8-22-117.8-87.2 0-59.2 58.6-81.1 109.1-81.1 55.1 0 110.8 21.9 110.8 55.4 0 16.9-11.4 31.8-30.3 31.8-28.3 0-29.2-33.5-75-33.5-25.7 0-42 7-42 22.5 0 19.8 20.8 21.8 69.1 33 41.4 9.3 90.7 26.8 90.7 77.6 0 59.1-57.1 86.5-112 86.5z"></path></svg></a></li></ul><ul class="copyright"><li>© Copyright 2020 Nobuhiro Ueda</li><li>Design by<!-- --> <a title="Styleshout" href="http://www.styleshout.com/">Styleshout</a></li></ul></div><div id="go-top"><a class="smoothscroll" title="Back to Top" href="/#home"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M240.971 130.524l194.343 194.343c9.373 9.373 9.373 24.569 0 33.941l-22.667 22.667c-9.357 9.357-24.522 9.375-33.901.04L224 227.495 69.255 381.516c-9.379 9.335-24.544 9.317-33.901-.04l-22.667-22.667c-9.373-9.373-9.373-24.569 0-33.941L207.03 130.525c9.372-9.373 24.568-9.373 33.941-.001z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"resumeData":{"main":{"name":"Nobuhiro Ueda","occupation":"NEC Corporation","description":"I am a researcher at the Data Science Laboratory, NEC Corporation. I received my Ph.D. in Informatics. I am working on R\u0026D of large language models and natural language processing.","image":"profile.jpg","email":"ueda at nlp.ist.i.kyoto-u.ac.jp","phone":"555-555-5555","address":{"street":"(Your Street)","city":"Kawasaki","state":"Kanagawa","zip":"211-0011"},"website":"https://nobu-g.github.io/","social":[{"name":"linkedin","url":"https://www.linkedin.com/in/nobuhiro-ueda-9163b91b7/","faClassName":"FaLinkedinIn"},{"name":"github","url":"https://github.com/nobu-g","faClassName":"FaGithub"},{"name":"skype","url":"https://skype.com","faClassName":"FaSkype"}]},"resume":{"education":[{"school":"Graduate School of Informatics, Kyoto University","degree":"Ph.D. of Informatics","graduated":"April 2021 - March 2024","description":"Worked on research about natural language processing."},{"school":"Graduate School of Informatics, Kyoto University","degree":"Master of Informatics","graduated":"April 2019 - March 2021","description":"Worked on research about natural language processing."},{"school":"Faculty of Engineering, Kyoto University","degree":"Bachelor of Engineering","graduated":"April 2015 - March 2019","description":"Learned about a wide range of engineering topics, including calculus, linear algebra, statistics, electronics, electromagnetism, and computer science."}],"publications":{"International Conferences and Workshops (Peer-reviewed)":[{"author":"Nobuhiro Ueda, Hideko Habe, Yoko Matsui, Akishige Yuguchi, Seiya Kawano, Yasutomo Kawanishi, Sadao Kurohashi and Koichiro Yoshino","title":"J-CRe3: A Japanese Conversation Dataset for Real-world Reference Resolution","misc":"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), Turin, Italy, (2024.5).","resource":{"paper":"https://arxiv.org/abs/2403.19259","dataset":"https://github.com/riken-grp/J-CRe3","code":"https://github.com/riken-grp/multimodal-reference","poster":"/pub/LREC-COLING2024_poster.pdf"}},{"author":"Yikun Sun, Zhen Wan, Nobuhiro Ueda, Sakiko Yahata, Fei Cheng, Chenhui Chu and Sadao Kurohashi","title":"Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese","misc":"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), Turin, Italy, (2024.5).","resource":{"paper":"https://arxiv.org/abs/2403.03690","dataset":"https://github.com/hitoshizuku7/awesome-Ja-self-instruct","code":"https://github.com/ku-nlp/ja-vicuna-qa-benchmark"}},{"author":"Nobuhiro Ueda, Kazumasa Omura, Takashi Kodama, Hirokazu Kiyomaru, Yugo Murawaki, Daisuke Kawahara and Sadao Kurohashi","title":"KWJA: A Unified Japanese Analyzer Based on Foundation Models","misc":"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023): System Demonstrations, Toronto, Canada, (2023.7).","resource":{"paper":"https://aclanthology.org/2023.acl-demo.52.pdf","code":"https://github.com/ku-nlp/kwja","demo":"https://lotus.kuee.kyoto-u.ac.jp/kwja/index","poster":"/pub/ACL2023_poster.pdf"}},{"author":"Nobuhiro Ueda and Sadao Kurohashi","title":"Improving Bridging Reference Resolution using Continuous Essentiality from Crowdsourcing","misc":"Proceedings of the Fifth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2022), Gyeongju, Republic of Korea, (2022.10).","resource":{"paper":"https://aclanthology.org/2022.crac-1.8.pdf","code1":"https://github.com/nobu-g/bridging-resolution","code2":"https://github.com/nobu-g/bridging-annotation","slides":"/pub/CRAC2022_slides.pdf"}},{"author":"Nobuhiro Ueda, Daisuke Kawahara and Sadao Kurohashi","title":"BERT-based Cohesion Analysis of Japanese Texts","misc":"Proceedings of the 28th International Conference on Computational Linguistics (COLING 2020), Online, (2020.12).","resource":{"paper":"/pub/COLING2020.pdf","code":"https://github.com/nobu-g/cohesion-analysis","errata":"/pub/COLING2020_errata.pdf"}},{"author":"Akiko Aizawa, Frederic Bergeron, Junjie Chen, Fei Cheng, Katsuhiko Hayashi, Kentaro Inui, Hiroyoshi Ito, Daisuke Kawahara, Masaru Kitsuregawa, Hirokazu Kiyomaru, Masaki Kobayashi, Takashi Kodama, Sadao Kurohashi, Qianying Liu, Masaki Matsubara, Yusuke Miyao, Atsuyuki Morishima, Yugo Murawaki, Kazumasa Omura, Haiyue Song, Eiichiro Sumita, Shinji Suzuki, Ribeka Tanaka, Yu Tanaka, Masashi Toyoda, Nobuhiro Ueda, Honai Ueoka, Masao Utiyama, Ying Zhong","title":"A System for Worldwide COVID-19 Information Aggregation","misc":"Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP 2020, Online, (2020.12).","resource":{"paper":"/pub/EMNLPWS2020.pdf","url":"https://lotus.kuee.kyoto-u.ac.jp/NLPforCOVID-19/en"}}],"Domestic Journals":[{"author":"植田 暢大, 波部 英子, 松井 陽子, 湯口 彰重, 河野 誠也, 川西 康友, 黒橋 禎夫, 吉野 幸一郎","title":"J-CRe3: 実世界における参照関係解決のための日本語対話データセット","misc":"自然言語処理, Vol31, No.3, (2024.9).","resource":{"paper":"https://www.jstage.jst.go.jp/article/jnlp/31/3/31_1107/_pdf/-char/ja"}}],"Domestic Conferences":[{"author":"稲積 駿, 植田 暢大, 吉野 幸一郎","title":"実世界対話における参照関係の統合的解析","misc":"言語処理学会 第31回年次大会, 長崎, (2025.3).","resource":{"paper":"https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q7-13.pdf","poster":"/pub/NLP2025_poster.pdf"}},{"author":"植田 暢大, 波部 英子, 松井 陽子, 湯口 彰重, 河野 誠也, 川西 康友, 黒橋 禎夫, 吉野 幸一郎","title":"実世界対話におけるフレーズグラウンディングモデルの評価と分析","misc":"言語処理学会 第30回年次大会, 神戸, (2024.3).","resource":{"paper":"https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/E1-4.pdf","slides":"/pub/NLP2024a_slides.pdf"}},{"author":"Namgi Han, 植田 暢大, 大嶽 匡俊, 勝又 智, 鎌田 啓輔, 清丸 寛一, 児玉 貴志, 菅原 朔, Bowen Chen, 松田 寛, 宮尾 祐介, 村脇 有吾, 劉 弘毅","title":"llm-jp-eval: 日本語大規模言語モデルの自動評価ツール","misc":"言語処理学会 第30回年次大会, 神戸, (2024.3).","resource":{"paper":"https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A8-2.pdf","slides":"/pub/NLP2024b_slides.pdf"}},{"author":"植田 暢大, 波部 英子, 湯口 彰重, 河野 誠也, 川西 康友, 黒橋 禎夫, 吉野 幸一郎","title":"実世界における総合的参照解析を目的としたマルチモーダル対話データセットの構築","misc":"言語処理学会 第29回年次大会, 沖縄, (2023.3).","resource":{"paper":"https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/H12-1.pdf","slides":"/pub/NLP2023_slides.pdf"},"award":{"name":"委員特別賞","image":"/images/award.png"}},{"author":"児玉 貴志, 植田 暢大, 大村 和正, 清丸 寛一, 村脇 有吾, 河原 大輔, 黒橋 禎夫","title":"テキスト生成モデルによる日本語形態素解析","misc":"言語処理学会 第29回年次大会, 沖縄, (2023.3).","resource":{"paper":"https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/C2-3.pdf","code":"https://github.com/ku-nlp/kwja"}},{"author":"植田 暢大, 大村 和正, 児玉 貴志, 清丸 寛一, 村脇 有吾, 河原 大輔 and 黒橋 禎夫","title":"KWJA：汎用言語モデルに基づく日本語解析器","misc":"情報処理学会 第253回自然言語処理研究会, 京都, (2022.9).","resource":{"paper":"https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main\u0026active_action=repository_view_main_item_detail\u0026item_id=220232\u0026item_no=1\u0026page_id=13\u0026block_id=8","code":"https://github.com/ku-nlp/kwja","slides":"https://speakerdeck.com/nobug/kyoto-waseda-japanese-analyzer"},"award":{"name":"優秀研究賞","image":"/images/award.png"}},{"author":"植田 暢大, 河原 大輔, 黒橋 禎夫","title":"BERTとRefinementネットワークによる統合的照応・共参照解析","misc":"言語処理学会 第26回年次大会, 茨城, (2020.3).","resource":{"paper":"/pub/NLP2020a.pdf"},"award":{"name":"若手奨励賞","image":"/images/award.png"}},{"author":"清丸 寛一, 植田 暢大, 児玉 貴志, 田中 佑, 岸本 裕大, 田中 リベカ, 河原 大輔, 黒橋 禎夫","title":"因果関係グラフ: 構造的言語処理に基づくイベントの原因・結果・解決策の集約","misc":"言語処理学会 第26回年次大会, 茨城, (2020.3).","resource":{"paper":"/pub/NLP2020b.pdf"}}],"Ph.D. Thesis":[{"author":"Nobuhiro Ueda","title":"Cohesion Analysis of Textual and Visual Entities: Enhancing Accuracy and Comprehensiveness","misc":"Ph.D. Thesis, Kyoto University, (2025.3).","resource":{}}]},"experience":{"researcher":[{"title":"NEC Corporation","place":"Kawasaki, Kanagawa","years":"April 2024 - Present","description":"","resource":{"website":"https://www.nec.com/"}}],"hackathon":[{"title":"16th Young Researcher Association for NLP Studies (YANS) Symposium Hackathon","place":"Online","years":"August 2021","description":"","resource":{"report":"https://yans.anlp.jp/entry/yans2021report","code":"https://github.com/upura/yans2021-hackathon"},"award":{"name":"2nd place","image":"/images/award.png"}}],"teaching assistant":[{"title":"「人を知る」人工知能講座2022","place":"Online","years":"November 2022","description":"","resource":{"website":"https://www.kyodai-original.co.jp/jinkouchinou2022/"}},{"title":"「人を知る」人工知能講座2021","place":"Online","years":"November 2021","description":"","resource":{"website":"https://www.kyodai-original.co.jp/jinkouchinou2021/"}},{"title":"C Programming Class (2021)","place":"Kyoto University, Kyoto","years":"April 2021 - July 2021","description":"","resource":{}},{"title":"「人を知る」人工知能講座2020","place":"Online","years":"November 2020","description":"","resource":{"website":"https://www.kyodai-original.co.jp/jinkouchinou2020/"}},{"title":"「人を知る」人工知能講座2019","place":"Shin-marunouchi Building, Tokyo","years":"November 2019","description":"","resource":{"website":"https://www.kyodai-original.co.jp/jinkouchinou2019/"}},{"title":"C Programming Class (2019)","place":"Kyoto University, Kyoto","years":"April 2019 - July 2019","description":"","resource":{}}],"internship":[{"title":"M3, Inc.","place":"Akasaka Intercity, Tokyo","years":"September 2019","description":"Worked on improving recommendation system for medical articles.","resource":{}},{"title":"LINE","place":"LINE KYOTO, Kyoto","years":"August 2019","description":"Joined a hackathon to develop an application like Akinator, which runs on LINE.","resource":{"report":"https://engineering.linecorp.com/ja/blog/kyoto-intern2019/"}}],"presentation \u0026 talks":[{"title":"日本語DeBERTaモデルの構築 (JLR2023)","place":"Okinawa Convention Center, Okinawa","years":"March 2023","description":"Gave a lightning talk on Japanese foundation models I developed.","resource":{"website":"https://jedworkshop.github.io/JLR2023/program/","slides":"/pub/JLR2023.pdf"}},{"title":"自然言語の意味理解に向けた名詞や述語間の関係解析","place":"15th ICT innovation, Kyoto University","years":"February 2021","description":"Gave a poster presentation on my research.","resource":{"website":"https://ict-nw.i.kyoto-u.ac.jp/ict-innovation/15th/","poster":"/pub/ICT_innovation_16th.pdf"}}]},"honors":[{"name":"Informatics, AI, and Data Science Fellowship for Doctoral Talent","years":"April 2021 - March 2024","resource":{"website":"https://www.i.kyoto-u.ac.jp/fellowship/"}},{"name":"2nd place in 16th Young Researcher Association for NLP Studies (YANS) Symposium Hackathon","years":"August 2022","resource":{"report":"https://yans.anlp.jp/entry/yans2021report","code":"https://github.com/upura/yans2021-hackathon"}}],"skills":[{"name":"Git","level":"70%"},{"name":"Python","level":"90%"}]},"portfolio":{"projects":[{"title":"kwja","category":"A unified language analyzer for Japanese","image":"kwja.png","url":"https://github.com/ku-nlp/kwja"},{"title":"cohesion-analysis","category":"A BERT based Japanese cohesion analyzer","image":"cohesion-analysis.png","url":"https://github.com/nobu-g/cohesion-analysis"},{"title":"10cc","category":"C compiler from scratch","image":"10cc.jpg","url":"https://github.com/nobu-g/10cc"},{"title":"Music-Game","category":"Rhythm video game for iOS","image":"music-game-kari.png","url":"https://github.com/chomin/Music-Game"}]}}},"__N_SSG":true},"page":"/","query":{},"buildId":"s-4YCiVsa_14CEoif0VFY","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>